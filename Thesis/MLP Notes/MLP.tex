% ================
% Landon Buell
% Kevin Short
% PHYS 799
% 18 May 2020
% ================

\documentclass[12pt,letterpaper]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage[left=2.5cm,right=2.5cm,top=2.5cm]{geometry}

\begin{document}


% ================================

\title{On the Functionality of the Multilayer Perceptron Classifier Neural Network Architecture}
\date{18 May 2020}
\author{Landon Buell}
\maketitle

% ================================================================

\section*{Introduction}

\paragraph*{}In 1943, neurophysiologist Warren McCulloch and mathematician Walter Pitts published \textit{A Logical Calculus of the Ideas Immanent in Nervous Activity} \cite{McCulloch}, which paved the way for the fields of computational neuroscience and early mathematical models of the brain. McCulloch and Pitts proposed that one could loosely mimic the behavior of a brain as a series of mathematical calculations. They realized that the smallest known element of the brain, a \textit{neuron}, acts as a simple on/off switch, much like computers have been designed to. Furthermore, single neurons by themselves do very little, but instead it is the organization of these cells into collections that make up functional networks \cite{Geron,Levine,McCulloch}. 

\paragraph*{}The mathematical model could be augmented by trading the simple Boolean (T/F) value, with a continuously ranging number referred to as an \textit{activation}. By producing different types of artificial neurons and establishing a series of synapses, it then became apparent that different organization of these elements could produce networks of solving increasingly advanced problems \cite{Goodfellow}. To further expand upon this, in 1957, Frank Rosenblatt created a neural network architecture called a Multilayer Perceptron (MLP), which uses layers of interacting neurons to create a single mathematical model \cite{Geron,Petrik}. This gives it a simple feed-forward design which has experimentally shown to perform well with tasks related to image and speech recognition \cite{Goodfellow,Loy}.

\paragraph*{}In general, the goal of an classification MLP is to produce some approximation function, $F^*$ that maps an array or vector of inputs, 
$\vec{x}$ to a set of discrete classes: $0,1,2,...,k-1$, using a set of parameters $\hat{\theta}$ \cite{Geron,Goodfellow,Petrik}. For a \textit{k-bins} classifier, we notate this as:

\begin{equation}
\label{approx}
F^* : \big\{ \vec{x},\hat{\theta}\big\} \rightarrow \big\{ 0,1,2,...,k-2,k-1 \big\}
\end{equation}

This function is in turn composed of layers of smaller repeating functions, which is what gives rise to the \textit{network} concept of the model. It is the chains of these smaller functions that allow for the producing of the approximate function $F^*$ to be created and solve a vast range of problems.


% ================================================================

\section*{Architecture}
\paragraph*{}To build a Multilayer Perceptron (MLP), artificial neurons need to be grouped into multiple structures, each called a \textit{layer}. A single layer is modeled mathematically as a column vector, $\vec{x}$ by convention:

\begin{equation}
\label{layer}
\vec{x}^{(l)} = \big[ x_0 , x_1 , x_2 , ... , x_{n-2} , x_{n-1} \big]^T
\end{equation}

The superscript $(l)$ is used to indicate the layer number of which this vector represents. Each element inside this vector is a neuron in the MLP model, and the value of that element is the neuron's \textit{activation} \cite{Geron}. In term of numerical handling, this structure is an array of floating-point numbers. A neural network can have any number of these layers in them, with any number of neurons in each layer. The number of these hidden layers is often referred to as the \textit{network depth} and the number of neurons in each layer is often called the \textit{neuron density} or \textit{network width}.

\paragraph*{}In addition to these layers, called \textit{hidden layers}, a neural network also requires an \textit{input layer} and an \textit{output layer}\cite{Goodfellow}. As the name implies, the input layer is where initial arrays of data are passed into the network. This array is often called a \textit{feature vector} as each element is a feature derived from a potentially larger data set. Typically, this feature vector is denoted by 
$\vec{x}^{(0)}$ is also the $\vec{x}$ object in equation (\ref{approx}). 

\paragraph*{}In a network with $L$ layers, the output array is also a vector, 
$\vec{x}^{(L-1)}$ which encodes the final decision made by the network model. In a k-bins classifier, there are $k$ neurons, each one corresponding to a different class. The neuron with the highest activation value corresponds to the networks prediction for what class the particular sample, 
$\vec{x}^{(0)}$ belongs to. If the output, $\vec{x}^{(L-1)}$ is appropriately normalized, then then activations can be interpreted percentage probabilities of which class the sample belongs to:

\begin{equation}
\label{probability}
P \big( \vec{x}^{(L-1)} \big) = \frac{1}{||\vec{x}^{(L-1)}||_2} \big[ x_0 , x_1 , x_2 , ... , x_{k-2} , x_{k-1} \big]^T
\end{equation}

\paragraph*{}In this network of $L$ layers, there are $L-2$ hidden layers whose activations are given by the entries in $\vec{x}^{(1)}$, 
$\vec{x}^{(2)}$ , ... , $\vec{x}^{(L-3)}$ , $\vec{x}^{(L-2)}$. And again, the input layers and output layers are given by $\vec{x}^{(0)}$ and 
$\vec{x}^{(L-1)}$ respectively. Throughout the duration of the model's construction, training and evaluation, these objects remain as column vectors / arrays of real floating point values.

\pagebreak

% ================================================================

\section*{Feed-Forward System}

\paragraph*{}Just by having systems of discrete layers, there is no way for the network to behave as a single model. Thus, we need to connect adjacent layers with synapses. These synapses, also called \textit{weights} allow each activation in any given layer to be a linear combination of the activation in the previous layer, with an addition \textit{bais} constant added \cite{Geron,Loy}. Keeping in mind the mathematical equivalent to vectors: we can then say that the $i$-th element in some layer $(l+1)$ is given by:

\begin{equation}
\label{single element}
x^{(l+1)}_i = b^{(l)}_i + \sum_{j} w^{(l)}_{ij} x^{(l)}_j
\end{equation}

Where $b^{(l)}_i$ is the bias entry, $w^{(l)}_{ij}$ is the weight coefficient that joins neuron $x_j$ to neuron $x_i$,m adn $x_j$ is the activation of the $j$-th neuron.  Notice how the combination of elements in layer $(l)$, given by the upper index, combine to produce the $i$-th neuron activation in layer $(l+1)$. 

\paragraph*{}Suppose there are $m$ elements in layer $(l)$ and $n$ elements in layer $(l+1)$. We can then express all activations in layer $(l+1)$ by expanding out the sum into a system of linear combinations:
\begin{equation}
\begin{split}
\label{system elements}
x^{(l+1)}_0 &= b^{(l)}_0 + w^{(l)}_{0,0} x^{(l)}_0 + w^{(l)}_{0,1} x^{(l)}_1 + \hdots + w^{(l)}_{0,m-1} x^{(l)}_{m-1}  \\
x^{(l+1)}_1 &= b^{(l)}_1 + w^{(l)}_{1,0} x^{(l)}_1 + w^{(l)}_{1,1} x^{(l)}_1 + \hdots + w^{(l)}_{1,m-1} x^{(l)}_{m-1}  \\
\vdots & \text{\hspace{2cm}} \vdots \\
x^{(l+1)}_{n-1} &= b^{(l)}_{n-1} + w^{(l)}_{1,0} x^{(l)}_{n-1} + w^{(l)}_{n-1,1} x^{(l)}_{n-1} + \hdots + w^{(l)}_{n-1,m-1} x^{(l)}_{m-1}  \\
\end{split}
\end{equation}

\paragraph*{}To make this more convenient to read and express mathematically, the entirety of the system (\ref{single element}) can be expresses as a single matrix vector product. The elements $x^{(l+1)}_i$ and $x^{(l)}_j$ can be concatenated in column vectors, $\vec{x}^{(l+1)}$ and $\vec{x}^{(l)}$ respectively:

\begin{equation}
\label{2 layers}
\begin{split}
\vec{x}^{(l)} 	&= \big[ x^{(l)}_0 , x^{(l)}_1 , x^{(l)}_2 , ... , x^{(l)}_{m-2} , x^{(l)}_{m-1} \big]^T \\
\vec{x}^{(l+1)} &= \big[ x^{(l+1)}_0 , x^{(l+1)}_1 , x^{(l+1)}_2 , ... , x^{(l+1)}_{n-2} , x^{(l+1)}_{n-1} \big]^T 
\end{split}
\end{equation}

Similarly, we can take all elements $w^{(l)}_{ij}$ and organize them into a single matrix object, which we call $\hat{W}^{(l)}$, defined as:

\begin{equation}
\label{weights}
\hat{W}^{(l)} = 
\begin{bmatrix}
w^{(l)}_{0,0} & w^{(l)}_{0,1} & w^{(l)}_{0,2} & \hdots & w^{(l)}_{0,m-2} & w^{(l)}_{0,m-1} \\
w^{(l)}_{1,0} & w^{(l)}_{1,1} & w^{(l)}_{1,2} & \hdots & w^{(l)}_{1,m-2} & w^{(l)}_{1,m-1} \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
w^{(l)}_{n-2,0} & w^{(l)}_{n-2,1} & w^{(l)}_{n-2,2} & \hdots & w^{(l)}_{n-2,m-2} & w^{(l)}_{n-2,m-1} \\
w^{(l)}_{n-1,0} & w^{(l)}_{n-1,1} & w^{(l)}_{n-1,2} & \hdots & w^{(l)}_{n-1,m-2} & w^{(l)}_{n-1,m-1} \\
\end{bmatrix}
\end{equation}

And finally, we define a bias vector, $\vec{b}^{(l)}$ for layer $(l)$, such that:

\begin{equation}
\label{bias}
\vec{b}^{(l)} = \big[ b^{(l)}_0 , b^{(l)}_1 , b^{(l)}_2 , ... , x^{(l)}_{n-2} , b^{(l)}_{n-1} \big]^T \\
\end{equation}

With these conventions established, we can then express the system (\ref{system elements}) as a matrix-vector product:

\begin{equation}
\label{mat-vec}
\vec{x}^{(l+1)} = \vec{b}^{(l)} + \hat{W}^{(l)} \vec{x}^{(l)}
\end{equation}

This linear equation is again, a compact way of expressing of expressing the linear relationship between activations in layer $(l)$ and layer $(l+1)$. However, this relationship only allows for a linear model as all activations are made of linear combinations. This is part of the justification as to why we have chosen to model layers of neuron activations as elements in column vectors in equation (\ref{layer}). 

\paragraph*{}Often, in many-real world problems, models confined to provide linear descriptions or create linear decision boundaries are often insufficient descriptions of solutions \cite{James}. To combat this, a \textit{non-linear activation function}, $f$, is added to the matrix vector product in equation (\ref{mat-vec}). This changes equation (\ref{mat-vec}) to become \cite{Goodfellow,Loy,Petrik} :

\begin{equation}
\label{mat-vec + act}
\vec{x}^{(l+1)} = f^{(l)} \Big( \hat{W}^{(l)} \vec{x}^{(l)} + \vec{b}^{(l)} \Big)
\end{equation}

Where $f^{(l)}$ is the activation function for the $l$-th layer. $\vec{x}^{(l+1)}$ has shape $n \times 1$ , $\hat{W}^{(l)}$ has shape $n \times m$, $\vec{x}^{(l)}$ has shape $m \times 1$ and $\vec{b}^{(l)}$ has shape $n \times 1$. (For conventional reasons, the baias vector has been moved to the other side of the matrix-vector product.) 

\paragraph*{}As the upper indexes imply, this is how the activations in the next layer are produced. By repeating this equation $L-1$ times in an 
$L$-layered network, information from the feature vector $\vec{x}^{(0)}$ can be successively transformed into the final decision output of the network $\vec{x}^{(L-1)}$. Each application of equation (\ref{mat-vec + act}) produces activations in each of the hidden layers. Note that in this $L$-layer network, there are $L-1$ weight matrices and $L-1$ bias vectors as well. Every single element in all of these arrays can be concatenated to form a larger object, $\hat{\theta}$. It is the combination of the elements in $\hat{\theta}$ that allow the network to map an input vector to an output vector as expressed in equation (\ref{approx}).

% ================================================================

\section*{Back Propagation System}

\paragraph*{}The logic of using and input $\vec{x}^{(0)}$ and set of parameters $\hat{\theta}$ to produce an output into a set of discrete bins $0$ thorough $k-1$ becomes worrisome when one considers the amount of parameters that make up the object $\hat{\theta}$, and furthermore how to produce these parameters such that the resulting approximation $F^*$ shows experimental validity. To remedy this, the model needs some way of using inputs, with known outputs, to find the elements of $\hat{\theta}$ that allow similar, but non-identical inputs to be mapped to correct outputs.

\paragraph*{}To do this, we must treat the behavior of a neural network as an optimization problem. The goal of this would then be to find the set of parameters $\hat{\theta}$ that produces the smallest possible output of some \textit{error function}, \cite{Goodfellow,James,Loy}. This may also be called a \textit{cost function} or \textit{loss function} as well. This function , $J$ takes the predicted output of the network $\vec{x}^{(L-1)}$ and the parameters $\hat{\theta}$ and maps it to a real number, which then measures the \textit{cost} of that particular sample such that:

\begin{equation}
\label{cost func}
J : \big\{ \vec{x}^{(L-1)}} \rightarrow \big\{ \mathbb{R} \big\}
\end{equation}	

\paragraph*{}The larger the value outputted from this function $J$, the further the models prediction differed from the expected value. Thus, this function can be through of as a measurement of how \textit{poor} the network's prediction was. It then becomes appropriate to make the goal of the model to \textit{optimize} $J$, with respect the parameters $\hat{\theta}$ to allow for a generally low cost value for a given input.

\paragraph*{}There are many ways to optimize the parameters in a neural network,for this work, we will examine an optimizer algorithm called \textit{Stochastic Gradient Descent} (SGD). This is an iterative method that uses repeated a passes over a data set to slowly push the cost function to a smaller and smaller value. As the name implies, we compute the gradient of the cost function, which its the partial derivative of each element that makes up the function, at a given step. 

\paragraph*{}To compute the gradient of the cost function, we have to examine it's composition.


% ================================================================

\section*{Conclusion}


% ================================================================

\begin{thebibliography}{9}
\bibliographystyle{apalike}

\bibitem{Geron}
Géron Aurélien. \textit{Hands-on Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems}. O'Reilly, 2017.

\bibitem{Goodfellow}
Goodfellow, Ian, et al.\textit{Deep Learning}. MIT Press, 2017.

\bibitem{James}
James, Gareth, et al. \textit{An Introduction to Statistical Learning with Applications in R}. Springer, 2017.

\bibitem{Levine}
Levine, Daniel S. \textit{Introduction to Neural and Cognitive Modeling}. 3rd ed., Routledge, 2019.

\bibitem{Loy}
Loy, James , \textit{Neural Network Projects with Python}. Packt Publishing, 2019

\bibitem{McCulloch}
McCulloch, Warren S., and Walter Pitts. “A Logical Calculus of the Ideas Immanent in Nervous Activity.” \textit{The Bulletin of Mathematical Biophysics}, vol. 5, no. 4, 1943, pp. 115–133.

\bibitem{Petrik}
Petrik, Marek. “Introduction to Deep Learning.” Machine Learning. 20 April. 2020, Durham, New Hampshire.

\end{thebibliography}

% ================================================================

\end{document}