% ================
% Landon Buell
% Kevin Short
% PHYS 799
% 3 June 2020
% ================

\documentclass[12pt,letterpaper]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[left=2.5cm,right=2.5cm,top=2.5cm]{geometry}
\usepackage{fancyhdr}

% ================================================================

\pagestyle{fancy}
\fancyhf{}
\lhead{MLP Classifier Neural Network}
\rhead{Landon Buell}
\cfoot{\thepage}

\begin{document}

% ================================

\title{Time-Series and Frequency-Series Features for Musical Instrument Classification}
\date{3 June 2020}
\author{Landon Buell}
\maketitle

% ================================================================

\section{Introduction}


% ================================================================

\section{Time Series Features}

\paragraph*{}Time series features (also called time-domain or time-space features) are pieces of information that can be extracted, derived, or otherwise originate from a signal that in expressed with a dependence on time. This can include weather forecasts, year-to-year population of a given demographic, audio information, or economic stock data. In the context of audio data, this is generally referred to as a \textit{waveform}. Given that time-series data (and all data) stored digitally must contain evenly-spaced, discrete samples, $S$ is used to indicate a signal stored in an array-like object with it's elements $S_i$ (where $i \in \{ 0,1,2,...,N-2,N-1\}$) make up the waveform.

% ================================


\subsection{Rise and Decay Time}

\paragraph*{}Signal \textit{rise time} measures the amount of time it takes for a time-domain signal, $S$, to leave it's steady-state condition and \textit{rise} to a given maximum $\max\big[|S|\big]$. Signal \textit{decay time} measures the amount of time it takes for a time-domain signal, $S$, to \textit{decay} from a given maximum value and return to it's steady-state value. Due to the nature of digitally stored audio in both time and amplitude, it may be impossible to find entries in the signal that satisfy exact equilibrium values (usually, $0$).

\paragraph*{}To account for this, we employ a function within our feature-extraction program that measures the $10\%$ to $90\%$ amplitude rise time, and the subsequent $90\%$ to $10\%$ amplitude decay time. This means that we produce two array-like objects for each signal. The first array will hold the position (or index) of all points that have a value that exceeds $90\%$ of the waveform maximum (accounting for negative amplitudes as well). The second array contains similarly index of values that exceed $10\%$ of the maximum, but not $90\%$.

\paragraph*{}If we take the difference between the $0$-th entry of each array, this is the number of samples that it took for the signal to reach (roughly) $10\%$ of it's maximum amplitude to (roughly) $90\%$ - this \textit{rise time}, $\Delta t_{R}$. Similarly, if we take the difference between the final entry in each array, this gives the \textit{decay time}, $\Delta t_{D}$. Both measurements are in units of the \textit{number of samples}; to convert into more traditional units of time (e.g. seconds), one can multiply by the spacing between samples or divide by the sample rate.


\begin{algorithm}
\label{Rise-Decay Time}
\caption{Compute amplitude rise and decay time of a discrete time-domain signal $S$ for a give lower bound percentage and upper bound percentage. Note that this uses a brute-force,loop through the full signal. Optimization methods for longer signals are encouraged}

\begin{algorithmic}

\REQUIRE Discrete time series signal: $S$ of length $N$
\REQUIRE Value to consider lower bound percentage (0,1): \textit{low\_bnd}
\REQUIRE Value to consider upper bound percentage (0,1): \textit{high\_bnd}
\ENSURE low\_bnd $<$ high\_bnd \\

$S \leftarrow |S|$ \\
max\_amp $\leftarrow$ maximum($S$) \\
above\_upper $\leftarrow \{ \}$ \\
above\_lower $\leftarrow \{ \}$ \\
\FOR {$i = 0,1,2,...,N-2,N-1$}
\item iterate through time, and add \textit{index values} to respective lists
\IF {$S_i \geq$ high\_bnd}
		\STATE above\_upper.insert($i$)
		\ELSIF {$S_i \leq$ high\_bnd \AND $S_i \geq$ low\_bnd}
		\STATE above\_lower.insert($i$)
		\ELSE
		\STATE continue
\ENDIF
\ENDFOR \\
M $\leftarrow$ $||$ above\_lower$_{(0)}$ - above\_lower$_{(-1)}$ $||$ - Length of active waveform by number of samples \\
risetime $\leftarrow$ $||$ above\_upper$_{(0)}$ - above\_lower$_{(0)}$ $||$/M - Rise time \\
decaytime $\leftarrow$ $||$ above\_upper$_{(-1)}$ - above\_lower$_{(-1)}$ $||$/M - Decay time \\
\RETURN risetime , decaytime
\end{algorithmic}
\end{algorithm}

\paragraph*{}Additionally, notice we normalize both rise and decay time with respect to the amount of samples between the initial rise and the final decay. We do this to eliminate dependence on absolute sample difference. If a signal is truncated, contains excessive quiet time or additional zero-padding, the interpretation of rise/decay time is then changed to a percentage or fraction of total active-waveform time.


% ================================


\subsection{Time-Frames}

\paragraph*{}A \textit{frame} is a unit of time discussed by Khan \& Al-Kathib and Liu.  \cite{Kahn 2006,Liu 1998}. Each frame is a collection of points from a discrete time-series waveform that have been concatenated into a new, smaller object. For frames of smaller length, a single waveform can produce hundreds or thousands of frames, where larger frame lengths may only permit dozens of frames from a waveform. The idea is to divide a waveform into sections with lower time resolution in order to extract additional features. A discrete signal $S$ can be decomposed into frames $s$ such that:

\begin{equation}
\label{many frames}
S = \big[ s_0 , s_1 , s_2 , .... , s_{N-2} , s_{N-1} \big]
\end{equation}

Where a single entry $s_i$ contains a subset of samples from the greater signal $S$, and can function as it's own discrete time-series object. Frames can also can also be overlapping or non-overlapping. It is recommended to use over-lapping frames when producing a spectrogram-like object or producing some sort of energy-amplitude envelope. We outline an algorithm that extracts an array-like object of frames from a signal $S$ using freame of fixed length:

\begin{algorithm}
\label{Time-Frames}
\caption{Use discrete signal $S$ to produce an array-like object $X$ of time-frame signals of fixed length.}
\begin{algorithmic}
\REQUIRE Discrete time series signal: $S$ of length $N$
\REQUIRE Number of samples per frame: $k$. Recc. $\log_2(k) \in \mathbb{Z}$
\REQUIRE Percentage of frame overlap: $L$ with $L \in [0,1)$
\ENSURE $N/k \in \mathbb{Z}$ - Use zero-padding or truncation. This ensures that no frames are partially filled \\
dt $\leftarrow k * (1 - L)$ - integer step size \\
X $\leftarrow \{\}$ - array to hold all frame arrays \\

\FOR {$i = 0$ \textbf{to} $i = (N-k-1)$ \textbf{step} dt}
	\item Create frame using index $i$ to $i+k$ from signal $S$
	\STATE frame $\leftarrow \big{\{} S[i:i+k] \big{\}}$ 
	\STATE X.insert(frame)
\ENDFOR

\RETURN X

\end{algorithmic}
\end{algorithm}

\paragraph*{}When constructing frames from is signal $S$ of $N$ samples, a designer can choose to use produce a set number of frames, or a set number of sample per frame. When choosing a fixed number of frames, $m$, there will be $N/m$ samples in each frame. When choosing a fixed number of sample per frame, $k$, there will be $N/k$ frames. It is necessary to truncate or pad the signal $S$ such that either $N/m \in \mathbb{Z}$ or $N/k \in \mathbb{Z}$. It is important to note that the frames themselves are not classification features, but are a vital step in deriving further classification features.

% ================================

\subsection{Waveform RMS Energy}

\paragraph*{}The Root-mean-squared energy (RMS)of a waveform can be used to approximate the average power in a waveform using Hooke's Law. The RMS of some discrete function $S$ with $N$ samples is given by:

\begin{equation}
\label{RMS}
S_{RMS} = \sqrt{\frac{1}{N}\sum_{i=0}^{N-1}S_i^2}
\end{equation}


% ================================

\subsection{Time Spectral Flux}

\paragraph*{}Time-Spectral-Flux (TSF) is a feature proposed by \cite{Kahn 2006}. It measures the magnitude of the incremental change between adjacent elements in a given sequence. For a discrete signal with unit sample rate, this can be loosely though of as a first-derivative approximation. Given a signal $S$ with $N$ samples, the TSF, $\Phi$, will be an array-like object $N-1$ samples. The $i$-th sample is given by:

\begin{equation}
\label{TSF}
\Phi_{i} = \big( S_{i+1} - S_{i} \big)
\end{equation} 

\paragraph*{}TSF can be used with the raw waveform signal $S$ directly, with time-frame-like objects $X$ or any other time-spectral array. Depending on the context, the right side of eqn. (\ref{TSF}) can be multiplied by come constant $c$ if values need to be scaled. This could be used to normalize the array, or to account for physical properties such as sample rate. In some cases, it may be beneficial to compute the magnitude of the difference between adjacent elements. Below we show an algorithm to compute TSF:

\begin{algorithm}
\label{TSF alg}
\caption{Compute Time-Spectral-Flux $\Phi$ of discrete signal $S$}
\begin{algorithmic}
\REQUIRE Discrete time series signal: $S$ of length $N$

$\Phi \leftarrow \{\}$
\FOR {$i = 0,1,2,...,N-3,N-2$}
	\STATE $\Phi$.insert($S[i+1] - S[i]$)
\ENDFOR

Optional: Apply additional functions or scaling. Normalization, scaling, absolute value, etc. can also be used and optimized depending on context \\
\RETURN $\Phi$

\end{algorithmic}
\end{algorithm}

\paragraph*{}Physically, TSF describes the frame-by-frame or index-by-index change in the shape of a spectrum. Signals containing speech have shown to have higher average spectral flux values than than of musical notes \cite{Kahn 2006,Zhang 1998}. Similarly, percussive instruments will demonstrate higher average frame TSF values than instruments that demonstrate greater sustain.

% ================================

\subsection*{Interval of Zero-Crossings}

\paragraph*{}Kahn \& Al-Kathib \cite{Kahn 2006} proposed a feature using the difference of maximum and minimum zero crossing in given time intervals as a feature vector when differentiating between speech and audio. This produced a much more distinct decision boundary than an ordinary zero crossing counter. Building on this, we count the number of zero crossing in each time-frame $X_i$.


% ================================================================

\section{Frequency Series Features}

\paragraph*{}Frequency series features (also called frequency-domain or frequency-space features) are peices of information that can be extracted, derived or otherwise originate from a signal that is expressed with a dependence on frequency. This is commonly done when needing to break down a give signal into it's simplest possible constituent frequency \cite{Peatross 2015}. We move a discrete signal of length $N$ that is a function of time, $S$, into a signal that is a function of frequency $F$, by applying the \textit{Discrete Fourier Transform} (DFT). This produces an array of $N$ complex-values numbers, the $k$-th element is given by:

\begin{equation}
\label{DFT}
F_{k} =  \sum_{n=0}^{N-1} S_{n} \cdot e^{-2\pi i\frac{kn}{N}}
\end{equation}

Where $F$ is an array Similarly, we recover the original time-basis signal $S$ with the \textit{Inverse Discrete Fourier transform} (IDFT). The $k$-th element is given by:

\begin{equation}
\label{IDFT}
S_{k} =  \frac{1}{N}\sum_{n=0}^{N-1} F_{n} \cdot e^{+2\pi i\frac{kn}{N}}
\end{equation}

\paragraph*{}Equations (\ref{DFT}) and (\ref{IDFT}) create a \textit{transform pair}.

% ================================

\subsection{Number of Unique, Isolated Peak}

\paragraph*{}Due to the physical properties of various musical instruments, there are often times when overtones from a pitch are not present in a waveform or the presence is very minuscule when producing the frequency spectrum.

% ================================

\subsection{Energy Spectral Density of Frequency Bands}

\paragraph*{}One of the most defining characteristics of the timbre of a sound is the it's distribution of power in frequency space. To do this, we divide a section of frequency space into multiple frequency \textit{banks}. Each bank is a subset of frequency space. Given the physical properties of vibrating strings, membranes and air columns, we know that successive overtones which appear are large isolated \textit{spikes} in the frequency domain tend to occur at positions that are integer multiples of the fundamental frequency.

\paragraph*{}By dividing frequency space into $k$ unique, non-overlapping banks, we can produce an estimate for the power of a musical instrument in each given band. For some signal $S$, represented in a frequency-basis $F$, we can compute the power \textit{energy spectral density} (ESD), $\mathbb{E}$ in the band from frequency $f'_a$ to $f'_b$ as given by:

\begin{equation}
\mathbb{E} = \sum_{i=f'_a}^{f'_b} |F_i|^2 df
\end{equation}

To improve numerical accuracy,this direct Reimann Summation can be replaced with a different integration method if desired. The resulting real floating-point number is the energy density of that signal in that given frequency band. We show an algorithm for computing the energy spectral density in of a frequency-space signal $F$.

\begin{algorithm}
\label{ESD}
\caption{Compute energy spectral density of banks in frequency space array $F$}
\begin{algorithmic}
\REQUIRE Discrete frequency series signal: $F$ of length $N$
\REQUIRE Array-like object: $x$, length $N$, maps each index of $F$ to a real-valued frequency bin.
\REQUIRE Array-like object: $P$, containing $k$ upper bound / lower bound pairs.
\REQUIRE Integration or summation function, method, or operation for array of discrete points: \textit{INTG}

\ENSURE $P$ array-object has shape $(k \times 2)$, with format resembling: \\
$P = \Big[ \{P_{(0,0)},P_{(0,1)}\} , \{P_{(1,0)},P_{(1 ,1)}\} ,  ... , \{P_{(k-1,0)},P{(k-1,1)}\} \Big]$\\
Where $P_{(i,0)}$ is the lower bound on bank $i$ and $P_{(i,1)}$ is the upper bound on bank $i$.\\
Initialize array-like object to the the Energy-Spectral-Density (ESD) of each frequency bank: \\
Bin\_ESDs $\leftarrow \{\}$

\FOR {$i = 0,1,2,...,k-2,k-1$}
	\item Iterate through each bank pair, find indecies where  
	\STATE low\_bnd , high\_bnd $\leftarrow$ $P_{(i,0)}$ , $P_{(i,1)}$
	\STATE idxs $\leftarrow \{ $\textbf{where} $x[j] \geq$ low\_bnd \AND $x[j] \leq$ high\_bnd $\}$
	\item Use entries in "idx" array to find the energy at the frequency band values, integrate the subset of the array to compute ESD of 
	\STATE E $\leftarrow \text{INTG}\big[ |F[\text{idxs}|^2 \Big]$
	\STATE Bin\_ESDs.insert(E)
\ENDFOR

\RETURN Bin\_ESDs
\end{algorithmic}
\end{algorithm}

\paragraph*{}The resulting array of floating-point numbers gives the energy spectral density distribution of the waveform in that frame of time. By choosing frames boundaries:

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
\textbf{Bounds} & 	\textbf{Bank 1} & \textbf{Bank 2} & \textbf{Bank 3} & \textbf{Bank 4} & 
					\textbf{Bank 5} & \textbf{Bank 6} & \textbf{Bank 7} & \textbf{Bank 8}  \\ \hline
\textbf{Low [Hz]}	& 0		& 32	& 64 & 128 & 256 & 512 & 1024 & 2048  		\\ 	\hline
\textbf{High [Hz]}	& 32	& 64	& 128 & 256 & 512 & 1024 &  2048 & 6000 	\\	\hline
\end{tabular}
\end{center}

These set of banks allow for a reasonable range such that every instrument contains at least one overtone in the frequency-spectrum for any given pitch played. This ESD distribution shows to be a valuable set of features for classification. Since this is largely what shapes human understanding of timbre, it is reasonable to use emphasise the importance of these features.

% ================================

% ================================

% ================================================================

\section{Combined Series Features}

% ================================

\subsection{Spectrogram Matrix}

% ================================

\subsection{Phase-Space Matrix}

% ================================



% ================================================================

\section{Additional Features}


% ================================================================

\section*{Summary}

% ================================================================

\begin{thebibliography}{9}
\bibliographystyle{apalike}

\bibitem{Kahn 2006}
Khan, M. Kashif Saeed, and Wasfi G. Al-Khatib. “Machine-Learning Based Classification of Speech and Music.” Multimedia Systems, vol. 12, no. 1, 2006, pp. 55–67., doi:10.1007/s00530-006-0034-0.

\bibitem{Liu 1998}
Liu, Zhu, et al. “Audio Feature Extraction and Analysis for Scene Classification.” Proceedings of First Signal Processing Society Workshop on Multimedia Signal Processing, 1998, pp. 61–79., doi:10.1109/mmsp.1997.602659.

\bibitem{Peatross 2015}
Peatross, Justin, and Michael Ware. \textit{Physics of Light and Optics}. Brigham Young University, Department of Physics, 2015.

\bibitem{Short 2006}
Short, Garcia, “Signal Analysis Using the Complex Spectral Phase Evolution (CSPE) Method”. Journal of the Audio Engineering Society.

\bibitem{Zhang 1998}
Zhang, Tong, and C.-C. Jay Kuo. “Content-Based Classification and Retrieval of Audio.” Advanced Signal Processing Algorithms, Architectures, and Implementations VIII, 2 Oct. 1998, pp. 432–443., doi:10.1117/12.325703.


\end{thebibliography}

% ================================================================

\end{document}