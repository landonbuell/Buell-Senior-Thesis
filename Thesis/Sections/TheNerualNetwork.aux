\relax 
\citation{Geron2}
\citation{Goodfellow}
\citation{Levine}
\citation{Goodfellow}
\citation{James}
\citation{Virtanen}
\citation{Geron}
\citation{Olsen}
\citation{White}
\@writefile{toc}{\contentsline {section}{\numberline {1}The Neural Network}{1}\protected@file@percent }
\newlabel{sec-TheNeuralNetwork}{{1}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}An Introduction to Neural Networks}{1}\protected@file@percent }
\citation{Goodfellow}
\citation{Loy}
\citation{Geron}
\citation{Loy}
\citation{Goodfellow}
\citation{Geron}
\citation{Loy}
\citation{Goodfellow}
\citation{Loy}
\citation{Geron}
\citation{James}
\citation{Loy}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}The Structure of a Neural Network}{2}\protected@file@percent }
\newlabel{eqn-FunctionChain}{{1}{2}}
\newlabel{eqn-LayerFunction}{{2}{2}}
\newlabel{eqn-altLayerFunction}{{3}{2}}
\citation{Goodfellow}
\citation{McCulloch}
\citation{Geron}
\citation{Geron}
\citation{Loy}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Layers Used in Classification Neural Network}{3}\protected@file@percent }
\newlabel{eqn-matVectEqn}{{4}{3}}
\newlabel{eqn-elementActivation}{{5}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Dense Layer}{3}\protected@file@percent }
\newlabel{layer-DenseNeurons}{{6}{3}}
\citation{Goodfellow}
\newlabel{eqn-DenseFeedForward}{{8}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}2-Dimensional Convolution Layer}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}2-Dimensional Maximum Pooling Layer}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.4}1-Dimensional Flattening Layer}{4}\protected@file@percent }
\newlabel{eqn-FlattenFunction}{{9}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.5}1-Dimensional Concatenation Layer}{4}\protected@file@percent }
\citation{Goodfellow}
\citation{Mitchell}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Training a Neural Network}{5}\protected@file@percent }
\newlabel{eqn-Theta}{{10}{5}}
\citation{Geron}
\citation{Khan}
\citation{Liu}
\citation{Loy}
\citation{Geron}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Chosen Model Architecture}{6}\protected@file@percent }
\citation{White}
\citation{Olsen}
\citation{Kahn}
\newlabel{fig-NetworkArchitecture}{{1.5}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The developed architecture of the audio file classification neural network. The Left branch process an image-like input, the right branch processes a vector-like input. The activations are then merged, and then a single output is produced}}{7}\protected@file@percent }
\citation{Geron}
\citation{Kahn}
\citation{Virtanen}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.1}The Spectrogram Branch}{8}\protected@file@percent }
\newlabel{eqn-shapeX1}{{11}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.2}The Perceptron Branch}{8}\protected@file@percent }
\newlabel{eqn-shapeX2}{{12}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.5.3}The Final Output Branch}{9}\protected@file@percent }
\bibstyle{apalike}
\bibcite{Geron}{1}
\bibcite{Geron2}{2}
\bibcite{Goodfellow}{3}
\bibcite{James}{4}
\bibcite{Kahn}{5}
\bibcite{Levine}{6}
\bibcite{Liu}{7}
\bibcite{Loy}{8}
\bibcite{McCulloch}{9}
\bibcite{Mierswa}{10}
\bibcite{Mitchell}{11}
\bibcite{Olsen}{12}
\bibcite{Peatross}{13}
\bibcite{Petrik}{14}
\bibcite{Short}{15}
\bibcite{Virtanen}{16}
\bibcite{White}{17}
\bibcite{Zhang}{18}
