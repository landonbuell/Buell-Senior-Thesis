\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}\protected@file@percent }
\newlabel{sec-Introduction}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methodology}{3}\protected@file@percent }
\newlabel{sec-Methodology}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Designing the Function}{3}\protected@file@percent }
\newlabel{eqn-MappingFunction}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Collecting and Pre-processing Raw Data}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Designing Classification Features}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Designing A Complementary Network Architecture}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Testing and Evaluating Network Performance}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Running Predictions of Chaotic Synthesizer Files}{4}\protected@file@percent }
\citation{Geron2}
\citation{Goodfellow}
\citation{Levine}
\citation{Virtanen}
\citation{Geron}
\citation{Geron}
\citation{Levine}
\citation{Geron}
\citation{Virtanen}
\citation{White}
\citation{Olson}
\citation{Goodfellow}
\citation{James}
\citation{Virtanen}
\citation{Goodfellow}
\citation{Loy}
\citation{Virtanen}
\@writefile{toc}{\contentsline {section}{\numberline {3}The Neural Network}{5}\protected@file@percent }
\newlabel{sec-TheNeuralNetwork}{{3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}An Introduction to Neural Networks}{5}\protected@file@percent }
\newlabel{subsec-NerualNetworkIntro}{{3.1}{5}}
\citation{Goodfellow}
\citation{Loy}
\citation{Geron}
\citation{Loy}
\citation{Goodfellow}
\citation{Geron}
\citation{Loy}
\citation{Geron}
\citation{Loy}
\citation{Geron}
\citation{James}
\citation{Loy}
\citation{Goodfellow}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}The Structure of a Neural Network}{6}\protected@file@percent }
\newlabel{subsec-NetworkStructure}{{3.2}{6}}
\newlabel{eqn-FunctionGraph}{{2}{6}}
\newlabel{eqn-FunctionChain}{{3}{6}}
\newlabel{eqn-altLayerFunction}{{4}{6}}
\citation{Goodfellow}
\citation{Geron}
\citation{Loy}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Forward propagation system in a standard deep neural network. Each layer is presumed to be a node in a linked computational graph. This example has been setup to assume one input layer, and one output layer. Practical implementations should include mini-batches of data as opposed to a single sample.\relax }}{7}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg-FeedForward}{{1}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Layers Used in this Classification Neural Network}{7}\protected@file@percent }
\newlabel{subsec-Layers}{{3.3}{7}}
\newlabel{eqn-LinearTransform}{{5}{7}}
\newlabel{eqn-LinearTransform2}{{6}{7}}
\citation{Geron2}
\citation{Loy}
\citation{McCulloch}
\citation{McCulloch}
\citation{Geron}
\citation{Loy}
\citation{Levine}
\citation{Geron}
\citation{Loy}
\citation{Goodfellow}
\newlabel{eqn-elementActivation}{{7}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Dense Layer}{8}\protected@file@percent }
\newlabel{subsubsec-DenseLayer}{{3.3.1}{8}}
\newlabel{layer-DenseNeurons}{{8}{8}}
\newlabel{eqn-FunctionDense}{{9}{8}}
\newlabel{eqn-DenseFeedForward}{{11}{8}}
\citation{Geron}
\citation{Loy}
\citation{Goodfellow}
\citation{Loy}
\citation{Goodfellow}
\citation{Geron}
\citation{Loy}
\citation{Goodfellow}
\citation{Goodfellow}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}2-Dimensional Convolution Layer}{9}\protected@file@percent }
\newlabel{subsubsec-Conv2DLayer}{{3.3.2}{9}}
\newlabel{eqn-convolution}{{12}{9}}
\citation{Goodfellow}
\citation{Geron}
\citation{Goodfellow}
\citation{Loy}
\citation{Loy}
\citation{Goodfellow}
\citation{Loy}
\citation{Loy}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The result of convolving an input (a) with an filter map (b) is a new set of activations (c). This Image was adapted from Goodfellow, pg. 325 \cite  {Goodfellow}\relax }}{10}\protected@file@percent }
\newlabel{fig-2DConvExample}{{1}{10}}
\newlabel{eqn-ConvFeedForward}{{14}{10}}
\citation{Geron}
\citation{Loy}
\citation{Goodfellow}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}2-Dimensional Maximum Pooling Layer}{11}\protected@file@percent }
\newlabel{subsubsec-2DPool}{{3.3.3}{11}}
\newlabel{fig-2DMaxPool}{{\caption@xref {fig-2DMaxPool}{ on input line 348}}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The result of 2D maximum-pooling an input array. This image was adapted from Loy, pg. 126 \cite  {Loy}\relax }}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.4}1-Dimensional Flattening Layer}{11}\protected@file@percent }
\newlabel{subsubsec-1DFlatten}{{3.3.4}{11}}
\newlabel{eqn-FlattenFunction}{{15}{11}}
\citation{Geron}
\citation{Loy}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.5}1-Dimensional Concatenation Layer}{12}\protected@file@percent }
\newlabel{subsubsec-1DConcat}{{3.3.5}{12}}
\newlabel{eqn-ConcatenationFunction}{{18}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Activation Functions Used in Network Layers}{12}\protected@file@percent }
\newlabel{sec-ActivationFunctions}{{3.4}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Rectified Linear Unit}{12}\protected@file@percent }
\newlabel{eqn-ReLU}{{19}{12}}
\citation{Geron}
\citation{Goodfellow}
\citation{Virtanen}
\citation{Loy}
\citation{Virtanen}
\citation{Goodfellow}
\citation{Mitchell}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Rectifed Linear Unit (ReLU) activation function\relax }}{13}\protected@file@percent }
\newlabel{fig-ReLU}{{3}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Softmax}{13}\protected@file@percent }
\newlabel{subsubsec-Softmax}{{3.4.2}{13}}
\newlabel{eqn-Softmax}{{20}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Training a Neural Network}{13}\protected@file@percent }
\newlabel{subsec-Training}{{3.5}{13}}
\citation{Geron}
\citation{Goodfellow}
\citation{Levine}
\citation{Goodfellow}
\citation{James}
\citation{James}
\citation{Goodfellow}
\citation{Virtanen}
\newlabel{eqn-Theta}{{21}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}The Cost Function}{14}\protected@file@percent }
\newlabel{eqn-CXELoss}{{22}{14}}
\newlabel{eqn-CXELossAvg}{{23}{14}}
\citation{Goodfellow}
\citation{James}
\citation{Loy}
\citation{Goodfellow}
\citation{Goodfellow}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Plot of how $y^*_{j}$ affects the output values of the CXE cost function\relax }}{15}\protected@file@percent }
\newlabel{fig-CXELoss}{{4}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}Gradient Based Learning}{15}\protected@file@percent }
\citation{Geron}
\citation{Goodfellow}
\citation{James}
\citation{Loy}
\citation{Geron}
\citation{Goodfellow}
\citation{Loy}
\newlabel{eqn-CostGradient}{{25}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3}Back-Propagation}{16}\protected@file@percent }
\newlabel{subsubsec-BackProp}{{3.5.3}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A visual representation of a simplified neural network as a computational graph\relax }}{17}\protected@file@percent }
\newlabel{fig-ComputationalGraph}{{5}{17}}
\citation{Loy}
\citation{Geron}
\citation{Goodfellow}
\newlabel{eqn-dWL1}{{27}{18}}
\newlabel{eqn-dbL1}{{28}{18}}
\newlabel{eqn-CXELossDeriv}{{29}{18}}
\citation{Geron2}
\citation{Goodfellow}
\newlabel{eqn-dWGeneral}{{34}{19}}
\newlabel{eqn-dbGeneral}{{35}{19}}
\citation{Geron}
\citation{Geron}
\citation{Geron}
\citation{Goodfellow}
\citation{Loy}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Backwards propagation system, in a standard densely connected deep neural network. Each iteration in the \textit  {for-loop} computes the gradient of the cost function $J$ with respect to the weight and bias arrays. Each element in those arrays $dW$ and $db$ is the discrete gradient of the cost due to that parameter. A practical application of this algorithm should include batches of samples instead of a single sample and a regularizing function at each step.\relax }}{20}\protected@file@percent }
\newlabel{algBackProp}{{2}{20}}
\newlabel{eqn-GradientLearning}{{36}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.4}The Optimizer}{20}\protected@file@percent }
\citation{Geron}
\citation{Geron}
\citation{Goodfellow}
\citation{Goodfellow}
\newlabel{eqn-ADAMupdate}{{37}{21}}
\citation{Goodfellow}
\citation{Virtanen}
\citation{Geron}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Adaptive-Moments (ADAM) optimizer for a neural network. This algorithm is adapted from Goodfellow, \cite  {Goodfellow}\relax }}{22}\protected@file@percent }
\newlabel{alg-ADAM}{{3}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Chosen Model Architecture}{22}\protected@file@percent }
\newlabel{subsec-Architecture}{{3.6}{22}}
\citation{White}
\citation{Olson}
\citation{Kahn}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The implemented miltimodal architecture of the audio file classification neural network. The Left branch process an image-like input, the right branch processes a vector-like input. The activations are then merged, and then a single output vector is produced\relax }}{23}\protected@file@percent }
\newlabel{fig-NetworkArchitecture}{{6}{23}}
\citation{Goodfellow}
\citation{Loy}
\citation{Geron}
\citation{Kahn}
\citation{Serizel}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1}The Spectrogram Branch}{24}\protected@file@percent }
\newlabel{eqn-shapeX1}{{38}{24}}
\citation{James}
\citation{Loy}
\citation{Geron}
\citation{James}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2}The Perceptron Branch}{25}\protected@file@percent }
\newlabel{eqn-shapeX2}{{39}{25}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.3}The Final Output Branch}{25}\protected@file@percent }
\citation{Virtanen}
\citation{Liu}
\citation{James}
\citation{Serizel}
\citation{Haberman}
\citation{Taylor}
\@writefile{toc}{\contentsline {section}{\numberline {4}Properties of Musical Instruments}{26}\protected@file@percent }
\newlabel{sec-Instruments}{{4}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Instruments categories used in the classification task. Note that the network uses only integers to indentify sources while the \relax }}{26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Idiophones}{26}\protected@file@percent }
\newlabel{subsec-Idiophone}{{4.1}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Membranophones}{26}\protected@file@percent }
\newlabel{subsec-membranophones}{{4.2}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Chordophones}{26}\protected@file@percent }
\newlabel{subsec-chordophones}{{4.3}{26}}
\citation{Olson}
\citation{White}
\citation{Haberman}
\citation{Haberman}
\citation{Haberman}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}The 1-Dimensional Vibrating String}{27}\protected@file@percent }
\newlabel{eqn-1DWaveEqn}{{40}{27}}
\citation{White}
\citation{White}
\citation{Virtanen}
\citation{White}
\citation{Olson}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Consequences of the Wave Equation}{28}\protected@file@percent }
\newlabel{eqn-RampFunc}{{47}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Aerophones}{28}\protected@file@percent }
\newlabel{subsec-Aerophones}{{4.4}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Other Generated Sounds}{28}\protected@file@percent }
\newlabel{subsec-Generated}{{4.5}{28}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Sine Wave}{28}\protected@file@percent }
\newlabel{eqn-SineWave}{{48}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces A sine wave in the (a) time-domian and (b) frequency domain\relax }}{28}\protected@file@percent }
\newlabel{fig-SineWave}{{8}{28}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2}Sawtooth Wave}{28}\protected@file@percent }
\citation{White}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.3}Square Wave}{29}\protected@file@percent }
\newlabel{eqn-SquareWave}{{49}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces A square wave in the (a) time-domain and (b) frequency domain\relax }}{29}\protected@file@percent }
\newlabel{fig-SquareWave}{{9}{29}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.4}Triangle Wave}{29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.5}White Noise}{29}\protected@file@percent }
\citation{James}
\citation{Loy}
\citation{Serizel}
\citation{Khan}
\citation{Olson}
\citation{Virtanen}
\citation{Liu}
\citation{Serizel}
\citation{Goodfellow}
\citation{James}
\citation{Mierswa}
\citation{Virtanen}
\@writefile{toc}{\contentsline {section}{\numberline {5}Feature Selections}{30}\protected@file@percent }
\newlabel{sec-Features}{{5}{30}}
\citation{Geron}
\citation{Goodfellow}
\citation{Loy}
\citation{Zerizel}
\citation{Tensorflow}
\citation{Loy}
\citation{Geron2}
\citation{James}
\citation{Virtanen}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.0.1}The Design Matrix}{32}\protected@file@percent }
\newlabel{eqn-X1Shape}{{51}{32}}
\newlabel{eqn-X2Shape}{{52}{32}}
\newlabel{eqn-YShape}{{53}{32}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.0.2}Audio Preprocessing}{32}\protected@file@percent }
\newlabel{subsubsec-Preprocessing}{{5.0.2}{32}}
\citation{Geron}
\citation{Goodfellow}
\citation{Loy}
\citation{Mierswa}
\citation{Liu}
\citation{Zhang}
\citation{Kahn}
\citation{Serizel}
\citation{Liu}
\citation{Liu}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Spectrogram Features}{34}\protected@file@percent }
\newlabel{subsec-spectrogram}{{5.1}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Spectrogram representations of various waveforms\relax }}{34}\protected@file@percent }
\newlabel{fig-spectrograms}{{10}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces A visualization of how frame-blocking is used to create each analysis frames. This image has been adapted and modified from Liu, et. al. "Audio Feature Extraction and Analysis", Fig. (1). See ref. \cite  {Liu}.\relax }}{35}\protected@file@percent }
\newlabel{fig-AnalysisFrames}{{11}{35}}
\newlabel{eqn-FrameMatrix}{{54}{35}}
\newlabel{eqn-IndexingA}{{55}{35}}
\newlabel{eqn-Hanning}{{56}{35}}
\citation{Virtanen}
\citation{Olson}
\citation{Peatross}
\citation{Virtanen}
\newlabel{eqn-WindowMatrix}{{57}{36}}
\citation{Short}
\citation{Peatross}
\citation{Olson}
\citation{Virtanen}
\citation{White}
\newlabel{eqn-DFTMatrix}{{58}{37}}
\newlabel{eqn-DFT}{{59}{37}}
\newlabel{eqn-Spectrogram}{{60}{37}}
\newlabel{eqn-IndexingS}{{61}{37}}
\newlabel{eqn-X1}{{62}{38}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Time-Space Features}{38}\protected@file@percent }
\newlabel{subsec-time}{{5.2}{38}}
\citation{Liu}
\citation{Olson}
\citation{Serizel}
\citation{Olson}
\citation{White}
\citation{Kahn}
\citation{Liu}
\citation{Zhang}
\citation{Serizel}
\citation{Liu}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Time Domain Envelope}{39}\protected@file@percent }
\newlabel{eqn-RMS}{{63}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces A comparison of the Time Domain Envelope across each class using a box-and-whisker plot\relax }}{39}\protected@file@percent }
\newlabel{fig-FeatureTDE}{{13}{39}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Zero Crossing Rate}{39}\protected@file@percent }
\citation{White}
\citation{Olson}
\citation{White}
\newlabel{eqn-ZXR}{{64}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces A comparison of the Zero-Crossing Rate for each class using a box-and-whisker plot\relax }}{40}\protected@file@percent }
\newlabel{fig-FeatureZXR}{{14}{40}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Temporal Center of Mass}{40}\protected@file@percent }
\newlabel{eqn-FeatureTCM}{{65}{40}}
\citation{Serizel}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces A comparison of the temporal center mass for each class using a box-and-whisker plot\relax }}{41}\protected@file@percent }
\newlabel{fig-FeatureTCM}{{15}{41}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.4}Auto Correlation Coefficients}{41}\protected@file@percent }
\newlabel{eqn-FeatureACC}{{66}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces A comparison of the the first four auto correlation coefficents in each class using a box-and-whisker plot\relax }}{42}\protected@file@percent }
\newlabel{fig-FeatureACC}{{16}{42}}
\citation{Sahidullah}
\citation{Serizel}
\citation{Sahidullah}
\citation{Serizel}
\citation{Serizel}
\citation{Kahn}
\citation{Serizel}
\citation{Kahn}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Frequency-Space Features}{43}\protected@file@percent }
\newlabel{subsec-frequency}{{5.3}{43}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Mel Filter Bank Energies}{43}\protected@file@percent }
\newlabel{eqn-HztoMel}{{67}{43}}
\newlabel{eqn-MeltoHz}{{68}{43}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Mel Filter Banks shown in frequency space with units of (a) Mels and (b)Hertz\relax }}{43}\protected@file@percent }
\newlabel{fig-MelFilterBanks}{{17}{43}}
\citation{Serizel}
\citation{Sahidullah}
\citation{Virtanen}
\citation{Serizel}
\citation{Sahidullah}
\citation{Liu}
\newlabel{eqn-FilterBanks}{{69}{44}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Mel Frequency Cepstral Coeffecients}{44}\protected@file@percent }
\newlabel{feat-MFCC}{{70}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces A comparison of 4 Mel Frequency Cepstral Coefficients, $1$, $4$, $8$ and $12$ for each class using box-and-whisker plots\relax }}{45}\protected@file@percent }
\newlabel{fig-FeatureMFCCs}{{18}{45}}
\citation{Olson}
\citation{White}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Frequency Center of Mass}{46}\protected@file@percent }
\newlabel{eqn-FeatureFCM}{{71}{46}}
\newlabel{fig-FeatureFCM}{{\caption@xref {fig-FeatureFCM}{ on input line 1396}}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces A comparison of the frequency center-of-mass for each class using box-and-whisker plots\relax }}{46}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Assembling the Design Matrices}{46}\protected@file@percent }
\newlabel{subsec-AssembleXs}{{5.4}{46}}
\citation{Geron}
\citation{Goodfellow}
\citation{Geron2}
\citation{Mitchell}
\citation{Geron}
\citation{Geron}
\citation{James}
\@writefile{toc}{\contentsline {section}{\numberline {6}Evaluating Model Performance}{47}\protected@file@percent }
\newlabel{sec-PerfEval}{{6}{47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}K-Folds Cross Validation}{47}\protected@file@percent }
\newlabel{subsec-XValidation}{{6.1}{47}}
\newlabel{eqn-XValSplit}{{73}{47}}
\citation{James}
\citation{Geron}
\citation{Geron}
\citation{Goodfellow}
\citation{James}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces A $K$-Fold Cross Validation program.\relax }}{48}\protected@file@percent }
\newlabel{alg-CrossValidation}{{4}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Performance Metrics}{48}\protected@file@percent }
\citation{Geron}
\citation{Geron}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Confusion Matrix}{49}\protected@file@percent }
\newlabel{eqn-ConfMat}{{6.2.1}{49}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Example Confusion Matrices for $k$-classes tasks\relax }}{49}\protected@file@percent }
\newlabel{fig-DummyConfMat}{{20}{49}}
\citation{Geron}
\citation{Geron}
\citation{Geron}
\citation{James}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Precision Score}{50}\protected@file@percent }
\newlabel{eqn-BinaryPrecision}{{74}{50}}
\newlabel{eqn-KPrecision}{{75}{50}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.3}Recall Score}{50}\protected@file@percent }
\newlabel{eqn-BinaryRecall}{{76}{50}}
\newlabel{eqn-KRecall}{{77}{50}}
\citation{Goodfellow}
\citation{Virtanen}
\citation{Geron}
\citation{Goodfellow}
\citation{Goodfellow}
\citation{James}
\citation{Loy}
\citation{Geron}
\citation{James}
\citation{Geron}
\citation{Goodfellow}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.4}Accuracy Score}{51}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Tracking Metrics over a Period of Training}{51}\protected@file@percent }
\newlabel{subsec-TrainingMetrics}{{6.3}{51}}
\@writefile{toc}{\contentsline {paragraph}{}{51}\protected@file@percent }
\citation{James}
\citation{Geron}
\citation{James}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces The loss function score decreases with each training step, indicating that optimization is performing correctly\relax }}{52}\protected@file@percent }
\newlabel{fig-LossScore}{{21}{52}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces The precision score (a) and recall score (b) increases with each training step\relax }}{52}\protected@file@percent }
\newlabel{fig-PrecisionRecallScores}{{22}{52}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Boosted Aggregation}{52}\protected@file@percent }
\newlabel{subsec-Bagging}{{6.4}{52}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Experimental Results}{54}\protected@file@percent }
\newlabel{sec-Results}{{7}{54}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{55}\protected@file@percent }
\newlabel{sec-Conclusion}{{8}{55}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Acknowledgments}{56}\protected@file@percent }
\newlabel{sec-Acknowledge}{{9}{56}}
\bibstyle{apalike}
\bibcite{Geron}{1}
\bibcite{Geron2}{2}
\bibcite{Goodfellow}{3}
\bibcite{Haberman}{4}
\bibcite{James}{5}
\bibcite{Kahn}{6}
\bibcite{Levine}{7}
\bibcite{Li}{8}
\bibcite{Liu}{9}
\bibcite{Loy}{10}
\bibcite{McCulloch}{11}
\bibcite{Mierswa}{12}
\bibcite{Mitchell}{13}
\bibcite{Ngiam}{14}
\bibcite{Olson}{15}
\bibcite{Peatross}{16}
\bibcite{Petrik}{17}
\bibcite{Powers}{18}
\bibcite{Sahidullah}{19}
\bibcite{Serizel}{20}
\bibcite{Short}{21}
\bibcite{Taylor}{22}
\bibcite{Tenorflow}{23}
\bibcite{Virtanen}{24}
\bibcite{White}{25}
\bibcite{Zhang}{26}
