{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating your First Multilayer Perceptron Classifier in Python w/ Scikit-Learn\n",
    "#### Landon Buell - 24 April 2020\n",
    "#### Adpated & Modified from \"Hands on Machine Learning with Scikit-Learn and Tensorflow\" by Aurelien Geron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multilayer Perceptron is a simple feed-forward architecture for neural networks developed by Frank Rosenblatt in the 1950's. It's composed of layers of \"neruons\" which we model as columns of floating-point numbers. The entries on each layer-vector object are referred to activations of the neruons in that layer. Information is passed through the network by repeated matrix- vector equations. \n",
    "\n",
    "Supose we have a column vector (M x 1) that contains activations for the $l$-th layer. We can produce the $l+1$ layer:\n",
    "$$ \\vec{x}^{(l+1)} = f \\Big[ \\hat{W}^{(l)} \\vec{x}^{(l)} + \\vec{b}^{(l)} \\Big] $$\n",
    "where $x^{(l+1)}$ is the activation vector (N x 1) for the next layer, $\\hat{W}$ is an (M x N) weighting matrix, $\\vec{b}$ is a (N x 1) bias vector, and $f$ is some activation function.\n",
    "\n",
    "For a network with $L$ layers (L-2 hidden, 1 input, 1 output), this equation is repeated $L-1$ times. The activations in the final layer correspond to the Network's final decision of a particular input sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rather than build one from the ground up:\n",
    "Let's explore the scikit-learn (sklearn) impliementation of the MLP network model. sklearn is a an open-source Python Module that has within it several smaller submodules that are all built around facilitaing a machine learning work flow for a Python 3.X user. The main documentation page can be found here:\n",
    "https://scikit-learn.org/stable/\n",
    "\n",
    "Before we import dive into sklearn, lets import some tools for later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.5\n",
      "0.21.3\n"
     ]
    }
   ],
   "source": [
    "#### PRELIMINARY IMPORTS ####\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "# program versions\n",
    "print(np.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Goal: Build a Digit-Image Classifier Neural Network\n",
    "For this example, we'll use the classifier variant to create a \"Digit-Detector Algorithm\" that identifies a digit within a 28 x 28 pixel picture.  To do this, we will use a standard toy data set called \"MNIST\". This is a data set modified from the US Postal service. You can find more details about it here:\n",
    "https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "We can actually load in this data set directly from sklearn! Note: Due to the size of the data set, your computer may take a few seconds to completely run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of design matrix: (70000, 784)\n",
      "Shape of target vector: (70000,)\n"
     ]
    }
   ],
   "source": [
    "#### LOAD IN RAW DATA SET ####\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "X,y = fetch_openml('mnist_784',version=1,return_X_y=True)\n",
    "\n",
    "# convert target entries to integers\n",
    "y = y.astype(np.uint64)\n",
    "\n",
    "# lets examine the shape of out data:\n",
    "print(\"Shape of design matrix:\",X.shape)\n",
    "print(\"Shape of target vector:\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that out design matrix $X$ is made of up $70,000$ rows by $784$ columns. This corresponds to $70,000$ samples in the data set, each one has 784 features, which are the 28 x 28 pixels. As a 'sanity check', lets examine what a sample looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image is labeled: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### EXAMINING A SINGLE SAMPLE OF DATA ####\n",
    "\n",
    "index = 10000\n",
    "# lets pull out a single row from the design matrix\n",
    "digit = X[index].reshape(28,28)\n",
    "# Lets pull out the corresponding label from the tagret vector:\n",
    "label = y[index]\n",
    "print(\"Image is labeled:\",label)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(digit,cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Step before building our network,\n",
    "Lets break data into training and testing samples, and we'll begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SPLIT INTO TRAINING & TESTING SAMPLES ####\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Sklearn MLP Classifier\n",
    "Now let's actually create a neural network! We'll use the \"MLPClassifier\" class object from the \"neural_network\" submodule.\n",
    "\n",
    "More on sklearn.neural_networks:\n",
    "https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "\n",
    "More on the MLPClassifier Object:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "\n",
    "When we create this instance, lets give our network 2 hidden layers, each with 100 neurons. Given our data set, the input layer with have 784 neurons, which we also call \"features\" (one for each pixel) and 10 output neurons, which we call \"classes\".\n",
    "Let's also use the \"ReLU\" activation function and the \"Stochastic Gradient Descent\" back propagation method to train the model as well. \n",
    "\n",
    "We will also set the \"random_state\" parameter to a fixed value so that we produce the same results from computer to computer. This parameter simply adjusts the initial values in the entries of each weighting matrix and bias vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CREATE SKLEARN NETWORK INSTANCE ####\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "My_Network = MLPClassifier(hidden_layer_sizes=(100,100),activation='relu',\n",
    "                          solver='sgd',random_state=0)\n",
    "\n",
    "# most of the other Hyper-parameters are taken care of for us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our Classifier\n",
    "Since each entry weighting matricies and bias vectors are initally random, we essentially have a very fancy random number generator! We need to train our model on the data. We do this by \"fitting\" the nerual network with the $X$ training subset and the corresponding $y$ subset. A network train's itself by adjusting the parameters in the weight matricies & bias vectors to minimize and error function (which we usually call a \"loss function\").\n",
    "\n",
    "It's worth noting that given our particular architect, the loss function of the network, and any decision it makes is a function of ~ 100,000 parameters. if you sum up the sizes of each weight matrix & bais vector, there are about ~99,610 different 'knobs' and 'dials' that we have to adjust in order to train this model. This means that we are optimizing a function in ~100,000 dimensional space!\n",
    "\n",
    "More on Stochastic Gradient Descent:\n",
    "https://en.wikipedia.org/wiki/Stochastic_gradient_descent\n",
    "\n",
    "The exact details behind back propagation training is a topic for another notebook (or a trip down the google-search rabbit hole), but for now, this is the general idea.\n",
    "\n",
    "Once agin, due to the volume of this data set and the computational complexity of the training process, the next cell make take a few seconds to fully run. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Landon\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#### TRAIN THE NEURAL NETWORK CLASSIFIER ####\n",
    "\n",
    "My_Network = My_Network.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on a Sample:\n",
    "We can run a precition on a single sample from the TESTING data set. This gaurentees that out classifier is making a predicitions on data that it has never seen before. Sometimes the predictions are accurate and sometimes they aren't. lets look as another sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image is labeled: 7\n",
      "Network prediction [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### PREDICTION A SINGLE SAMPLE OF DATA ####\n",
    "\n",
    "index = 1002\n",
    "# lets pull out a single row from the design matrix\n",
    "sample = X_test[index] \n",
    "digit = X_test[index].reshape(28,28)\n",
    "# Lets pull out the corresponding label from the tagret vector:\n",
    "label = y_test[index]\n",
    "print(\"Image is labeled:\",label)\n",
    "print(\"Network prediction\",My_Network.predict([sample]))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(digit,cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under the Hood - Using Linear Algbrea\n",
    "The exact weighting matricies and bais vectors can be extracted from the trained network instance. We can use these the \"manually\" re-create this prediction using repeated variation of the equation in the 2nd cell. Lets extract the matricies and manually assign them values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weighting Matrices: 3\n",
      "Number of bias Vector: 3\n",
      "\tMatrix shape: (784, 100)\n",
      "\tvector shape: (100,)\n",
      "\tMatrix shape: (100, 100)\n",
      "\tvector shape: (100,)\n",
      "\tMatrix shape: (100, 10)\n",
      "\tvector shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "#### EXACT WEIGHTING MATRICIES & BAIS VECTORS ####\n",
    "\n",
    "weights = My_Network.coefs_\n",
    "biases = My_Network.intercepts_\n",
    "print(\"Number of weighting Matrices:\",len(weights))\n",
    "print(\"Number of bias Vector:\",len(biases))\n",
    "\n",
    "# we can also examine the shapes\n",
    "for W,b in zip(weights,biases):\n",
    "    print(\"\\tMatrix shape:\",W.shape)\n",
    "    print(\"\\tvector shape:\",b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the linear algebra in action, lets \"hard-code\" the layers of the forward-propagations system. First, let's assign each matrix and vector it's own variable. And select a sample from the testing designmatic \"X_test\" to pass through the network manually. \n",
    "\n",
    "For more details on the ReLU activation function, please see:\n",
    "https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ASSIGN WEIGHTS & BIASES ####\n",
    "\n",
    "W0,W1,W2 = weights[0],weights[1],weights[2]\n",
    "b0,b1,b2 = biases[0],biases[1],biases[2]\n",
    "\n",
    "# define our activation function\n",
    "def ReLU(vec):\n",
    "    \"\"\" Rectified Linear Unit Activation Function for elements in vector\"\"\"\n",
    "    vec = vec.ravel()\n",
    "    for i in range(len(vec)):\n",
    "        if vec[i] <= 0.0:\n",
    "            vec[i] = 0.0\n",
    "    return vec.reshape(-1,1)\n",
    "        \n",
    "\n",
    "# Note that '@' is Python for standard matrix-multiplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (784, 1)\n",
      "Layer 1 shape: (100, 1)\n",
      "Layer 2 shape: (100, 1)\n",
      "Layer 3 shape: (10, 1)\n"
     ]
    }
   ],
   "source": [
    "#### FORWARD PASS THROUGH NETWORK ####\n",
    "\n",
    "# input feature vector, same sample as above\n",
    "x0 = sample.reshape(-1,1)\n",
    "print(\"Input shape\",x0.shape)\n",
    "\n",
    "# 1st hidden layer\n",
    "a1 = W0.T @ x0 + b0.reshape(-1,1)\n",
    "x1 = ReLU(a1)\n",
    "print(\"Layer 1 shape:\",x1.shape)\n",
    "\n",
    "# 2nd hidden layer\n",
    "a2 = W1.T @ x1 + b1.reshape(-1,1)\n",
    "x2 = ReLU(a2)\n",
    "print(\"Layer 2 shape:\",x2.shape)\n",
    "\n",
    "# output layer\n",
    "a3 = W2.T @ x2 + b2.reshape(-1,1)\n",
    "x3 = ReLU(a3)\n",
    "print(\"Layer 3 shape:\",x3.shape)\n",
    "\n",
    "# TIP: Checking the dimesnions of each object is a great way to make sure everything is running properly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now sucessfully pased the input vector through our neural network by simply repeating the equation from the 1st cell until we reach the output layer! Notice how along the way we've had to do some transposing and reshaping- this is just a property of how sklearn stores the numpy arrays efficiently. It's yet another reason why we have to very careful about the dimensions of our operators. Finally, let's check our prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network output for this sample:\n",
      "\n",
      "[ 0.          3.89227429  2.71098066 13.16824779  0.          0.\n",
      "  0.         22.77032281  0.         11.89063506] \n",
      "\n",
      "Manually predicted value: 7\n",
      "Recall predicted value from before: [7]\n"
     ]
    }
   ],
   "source": [
    "#### LAST LAYER ACTIVATIONS ####\n",
    "\n",
    "output_activations = x3.ravel()\n",
    "\n",
    "print(\"Network output for this sample:\\n\")\n",
    "print(output_activations,'\\n')\n",
    "\n",
    "# find the INDEX of the maximum activation\n",
    "max_entry = np.argmax(output_activations)\n",
    "\n",
    "print(\"Manually predicted value:\",max_entry)\n",
    "print(\"Recall predicted value from before:\",My_Network.predict([sample]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the final layer has 10 activation values. Recall that each one of these is representative of the 10 possible output classes 0 - 9. Since Python is a 0-indexed language, each element in the array is then perfectly correspondent to it's digit prediction (i.e. array[5] = '5' prediction). In most cases, things won't work out this nicely though. In the case of much deeper and complex networks, this forward process is  coded underneath a \"for-loop\" such that is can be generalized for any number of hidden layers. However, in the words of many great textbooks: \"This has been left and an excercise for the reader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-95-eb89292c2e9d>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-95-eb89292c2e9d>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# start with this bits of data:\n",
    "x0 = sample.reshape(-1,1)\n",
    "weights = My_Network.coefs_\n",
    "biases = My_Network.intercepts_\n",
    "n_layers = len(weights)\n",
    "\n",
    "for layer in range (n_layers):\n",
    "    # your code here!\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Cherry on Top: Evaluating the performance over many samples\n",
    "It's not very practical to run prediction based on single samples, so we can run the same built-in prediciton algorithm to run the forward pass on manyt different samples. Lets run these predictions on the testing subset and compare them to the actual, known values on the test subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [9 2 7 1 3 5]\n",
      "Target labels: [9 7 7 1 5 5]\n"
     ]
    }
   ],
   "source": [
    "#### RUN PREDICTIONS ON TEST SAMPLE SUBSET ####\n",
    "\n",
    "# predict on whole subset\n",
    "y_predictions = My_Network.predict(X_test)\n",
    "\n",
    "# Let's compare just a few of them together\n",
    "print(\"Predictions:\",y_predictions[0:6])\n",
    "print(\"Target labels:\",y_test[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### BUILD CONFUSION MATRIX ####\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test,y_predictions,labels=np.arange(0,10,1))\n",
    "\n",
    "plt.matshow(confusion,cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a \"confusion matrix\", color coded by the size of each entry. Darker squares have larger values, and lighter squares have lower values. Every row represents a predicted value, and every column is an actaul value - thus in our case it is a 10 x 10 matrix. Entries along the main diagonal are indicative of how many samples were predicted to below to a class, and actually do belong to that class. A good classifier model has a very strong main diagonal - as shown above!\n",
    "\n",
    "Each index of the confusion matrix, $C$, very specificially:\n",
    "$$C_{i,j}$$ \n",
    "Contains observations that actaully belong to class $i$, and were predicted to be in class $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We're Finished!\n",
    "Congrats, you've looked into how Neural networks behave and make decisions using only linear algebra! In reality, most architectures of networks (and yes, there are many different kinds), are just very clever alpplications of linear algebra and mathematical optimiziation. \n",
    "\n",
    "If you want a more inutitve, start-to-finish descriptiong of the math and the training process that we just examined in the notebook, check out Grant Sanderson's Youtube Channel \"3Blue1Brown\" and his video series on MLP Networks:\n",
    "https://www.youtube.com/watch?v=aircAruvnKk&t=369s\n",
    "\n",
    "If you want a book to read that does a very solid job introducing machine learning and neural networks with python, while being very math-light check out these:\n",
    "https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/\n",
    "https://www.oreilly.com/library/view/neural-network-projects/9781789138900/\n",
    "\n",
    "If you want a more theoretical and math-heavy introduction, Check this out:\n",
    "https://www.deeplearningbook.org/\n",
    "\n",
    "Otherwise, have fun with it, and learning something new! If you have any questions about this notebook, reach out to me at lhb1007@wildcats.unh.edu.\n",
    "\n",
    "Cheers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
