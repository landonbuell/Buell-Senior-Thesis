{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating your First Multilayer Perceptron Classifier in Python w/ Scikit-Learn\n",
    "#### Landon Buell - 24 April 2020\n",
    "#### Adpated & Modified from \"Hands on Machine Learning with Scikit-Learn and Tensorflow\" by Aurelien Geron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multilayer Perceptron is a simple feed-forward architecture for neural networks developed by Frank Rosenblatt in the 1950's. It's composed of layers of \"neruons\" which we model as columns of floating-point numbers. The enntries on each layer-vector object are referred to activations of for the neruons in that layer. Information is passed through the network by repeated matrix- vector equations. \n",
    "\n",
    "Supose we have a column vector (1 x M) that contains activations for the $l$-th layer. We can produce the $l+1$ layer:\n",
    "$$ x^{(l+1)} = f \\Big[ \\hat{W}^{(l)} \\vec{x}^{(l)} + \\vec{b}^{(l)} \\Big] $$\n",
    "where $x^{(l+1)}$ is the activation vector (1 x N) for the next layer, $\\hat{W}$ is an (N x M) weighting matrix, $\\vec{b}$ is a (1 x N) bias vector, and $f$ is some activation function.\n",
    "\n",
    "For a network with $L$ layers (L-2 hidden, 1 input, 1 output), this equation is repeated $L-1$ times. The activations in the final layer correspond to the Network's final decision of a particular input sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rather than build one from the ground up:\n",
    "Let's explore the scikit-learn (sklearn) impliementation of the MLP network model. sklearn is a an open-source API that has within it several smaller submodules that are all built around facilitaing a machine learning work flow for a Python 3.X user. The main documentation page can be found here:\n",
    "https://scikit-learn.org/stable/\n",
    "\n",
    "Before we import sklearn, lets import some tools for later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PRELIMINARY IMPORTS ####\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Goal: Build a Digit-Image Classifier Neural Network\n",
    "For this example, we'll use the classifier variant to create a \"Digit-Detector Algorithm\" that identifies a digit within a 28 x 28 pixel picture.  To do this, we will use a standard toy dataset called \"MNIST\". This is a data set modified fromt he US Postal service. You can find more details about it here:\n",
    "https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "We can actully load in thus data set directly from sklearn! Note: Due to the size of the dat set, your computer may take a few seconds to completely run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Design Matrix: (70000, 784)\n",
      "Shape of target Vector: (70000,)\n"
     ]
    }
   ],
   "source": [
    "#### LOAD IN RAW DATA SET ####\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "X,y = fetch_openml('mnist_784',version=1,return_X_y=True)\n",
    "\n",
    "# lets examine the shape of out data:\n",
    "print(\"Shape of design matrix:\",X.shape)\n",
    "print(\"Shape of target vector:\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that out design matrix $X$ is made of up $70,000$ rows by $784$ columns. This corresponds to $70,000$ samples in the data set, each one has 784 features, which are the 28 x 28 pixels. As a 'sanity check', lets examine what a sample looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image is labeled: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### EXAMINING A SINGLE SAMPLE OF DATA ####\n",
    "\n",
    "index = 10000\n",
    "# lets pull out a single row from the design matrix\n",
    "digit = X[index].reshape(28,28)\n",
    "# Lets pull out the corresponding label from the tagret vector:\n",
    "label = y[index]\n",
    "print(\"Image is labeled:\",label)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(digit,cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Step before building our network,\n",
    "Lets break data into training and testing samples, and we'll begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SPLIT INTO TRAINING & TESTING SAMPLES ####\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Sklearn MLP Classifier\n",
    "Now let's actually create a neural network! We'll use the \"MLPClassifier\" class object from the \"neural_network\" submodule.\n",
    "\n",
    "More on sklearn.neural_networks:\n",
    "https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "\n",
    "More on the MLPClassifier Object:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "\n",
    "When we create this instance, lets give our network 2 hidden layers, each with 100 neurons. Given our data set, the input layer with have 784 neurons, which we also call \"features\" (one for each pixel) and 10 output neurons, which we call \"classes\".\n",
    "Let's also use the \"ReLU\" activation function and the \"Stochastic Gradient Descent\" back propagation method to train the model as well. \n",
    "\n",
    "More on Stochastic Gradient Descent:\n",
    "https://en.wikipedia.org/wiki/Stochastic_gradient_descent\n",
    "\n",
    "We will also set the \"random_state\" parameter to a fixed value so that we produce the same results from computer to computer. This parameter simply adjusts the initial values in the entries of each weighting matrix and bias vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CREATE SKLEARN NETWORK INSTANCE ####\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "My_Network = MLPClassifier(hidden_layer_sizes=(100,100),activation='relu',\n",
    "                          solver='sgd',random_state=0)\n",
    "\n",
    "# most of the other Hyper-parameters are taken care of for us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our Classifier\n",
    "Since each entry weighting matricies and bias vectors are initally random, we essentially have a very fancy random number generator! We need to train out model on the data set. We do this by \"fitting\" the nerual network with the $X$ trainign subset and the corresponding $y$ subset. Once agin, due to the volume of this data set and the computational complexity of the training process, the next cell make take a few seconds to fully run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TRAIN THE NEURAL NETWORK CLASSIFIER ####\n",
    "\n",
    "My_Network = My_Network.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'softmax'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "My_Network.out_activation_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on a Sample:\n",
    "We can run a precition on a single sample from the TESTING data set. This gaurentees that out classifier is making a predicitions on data that it has never seen before. Sometimes the predictions are accurate and sometimes they aren't. lets look as another sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image is labeled: 0\n",
      "Network prediction ['0']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### PREDICTION A SINGLE SAMPLE OF DATA ####\n",
    "\n",
    "index = 1000\n",
    "# lets pull out a single row from the design matrix\n",
    "sample = X_test[index] \n",
    "digit = X_test[index].reshape(28,28)\n",
    "# Lets pull out the corresponding label from the tagret vector:\n",
    "label = y_test[index]\n",
    "print(\"Image is labeled:\",label)\n",
    "print(\"Network prediction\",My_Network.predict([sample]))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(digit,cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under the Hood - Using Linear Algbrea\n",
    "The exact weighting matricies and bais vectors can be extracted from the trained network instance. We can use these the \"manually\" re-create this prediction using repeated variation of the equation in the 2nd cell. Lets extract the matricies and manually assign them values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weighting Matrices: 3\n",
      "Number of bias Vector: 3\n",
      "\tMatrix shape: (784, 100)\n",
      "\tvector shape: (100,)\n",
      "\tMatrix shape: (100, 100)\n",
      "\tvector shape: (100,)\n",
      "\tMatrix shape: (100, 10)\n",
      "\tvector shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "#### EXACT WEIGHTING MATRICIES & BAIS VECTORS ####\n",
    "\n",
    "weights = My_Network.coefs_\n",
    "biases = My_Network.intercepts_\n",
    "print(\"Number of weighting Matrices:\",len(weights))\n",
    "print(\"Number of bias Vector:\",len(biases))\n",
    "\n",
    "# we can also examine the shapes\n",
    "for W,b in zip(weights,biases):\n",
    "    print(\"\\tMatrix shape:\",W.shape)\n",
    "    print(\"\\tvector shape:\",b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the linear algebra in action, lets \"hard-code\" the layers of the forward-propagations system. First, let's assign each matrix and vector it's own variable. And select a sample from the testing designmatic \"X_test\" to pass through the network manually. \n",
    "For more details on the ReLU activation function, please see:\n",
    "https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ASSIGN WEIGHTS & BIASES ####\n",
    "\n",
    "W0,W1,W2 = weights[0],weights[1],weights[2]\n",
    "b0,b1,b2 = biases[0],biases[1],biases[2]\n",
    "\n",
    "# define our activation function\n",
    "def ReLU(vec):\n",
    "    \"\"\" Rectified Linear Unit Activation Function for elements in vector\"\"\"\n",
    "    vec = vec.ravel()\n",
    "    for elem in vec:\n",
    "        if elem <= 0:\n",
    "            elem -= elem\n",
    "    return vec.reshape(-1,1)\n",
    "        \n",
    "\n",
    "# Note that '@' is Python for standard matrix-multiplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape (784, 1)\n",
      "Layer 1 shape: (100, 1)\n",
      "Layer 2 shape: (100, 1)\n",
      "Layer 3 shape: (10, 1)\n"
     ]
    }
   ],
   "source": [
    "#### FORWARD PASS THROUGH NETWORK ####\n",
    "\n",
    "# input feature vector, same sample as above\n",
    "x0 = sample.reshape(-1,1)\n",
    "print(\"Input shape\",x0.shape)\n",
    "\n",
    "# 1st hidden layer\n",
    "a1 = W0.T @ x0 + b0.reshape(-1,1)\n",
    "x1 = ReLU(a1)\n",
    "print(\"Layer 1 shape:\",x1.shape)\n",
    "\n",
    "# 2nd hidden layer\n",
    "a2 = ReLU(W1.T @ x1 + b1.reshape(-1,1))\n",
    "x2 = ReLU(a2)\n",
    "print(\"Layer 2 shape:\",x2.shape)\n",
    "\n",
    "# output layer\n",
    "a3 = W2.T @ x2 + b2.reshape(-1,1)\n",
    "x3 = ReLU(a3)\n",
    "print(\"Layer 3 shape:\",x3.shape)\n",
    "\n",
    "# TIP: Checking the dimesnions of each object is a great way to make sure everything is running properly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now sucessfully pased the input vector through our neural network by simply repeating the equation from the 1st cell until we reach the output layer! Notice how along the way we've had to do some transposing and reshaping- this is just a property of how sklearn stores the numpy arrays efficiently. It's yet another reason why we have to very careful about the dimensions of our operators. Finally, let's check our prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network output for this sample:\n",
      "\n",
      "[ 1329.78594357 -1243.01565051  1929.42060143  1882.59319622\n",
      "  1081.52750133 -1741.1441035   1382.83082564  -506.1972348\n",
      "    52.45654206   190.80076882]\n"
     ]
    }
   ],
   "source": [
    "#### LAST LAYER ACTIVATIONS ####\n",
    "output_activations = x3.ravel()\n",
    "print(\"Network output for this sample:\\n\")\n",
    "print(output_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
